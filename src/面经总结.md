# Java基础

## 1、内存泄露的原因，举例子，如何排查，OOM异常？

原因：内存泄露是指无用对象（不再使用的对象）持续占有内存或无用对象的内存得不到及时释放，从而造成内存空间的浪费成为内存泄露。内存泄露有不严重且不易排查，有时也会严重，会出现OOM异常

例子：

1、长生命周期的对象持有短生命周期的对象的引用，尽管短生命周期的对象不再使用，不能被GC回收。如静态的集合类，HashMap，LinkedList等等，如果这些容器是静态的，那么他们的生命周期与程序一致。

2、各种连接，数据库连接、网络连接、IO连接等，当不再使用时需要显示关闭，否则无法被GC回收

3、变量的作用域不合理

4、内部类持有外部类的引用

5、改变哈希值，如果一个对象被存入HashSet中，再后来又修改了参与哈希值计算的字段，则该对象在集合中无法被删除也无法被找到，造成内存泄露

排查：

查看GC状况

生成堆内存快照进行分析，看哪个对象占用内存大，对该对象代码段进行排查。

OOM异常共分为：

1、java堆溢出（Java heap space）

2、栈溢出（即栈容量无法容纳新的栈帧StackOverflowError，hotspot不允许动态扩展栈容量）

3、方法区和运行时常量池溢出（元空间溢出）

## 2、内部类会被编译成几个class？为什么内部类可以访问外部类的private方法？

会被分别编译，如果A为B的静态内部类，则A会被编译为B$A.class，内部类在创建时会传递一个外部类的引用，通过这个引用可以访问到外部类的private方法或属性，静态内部类则只能访问静态属性或方法，不能访问非静态属性或方法。

## 3、fail-safe和fail-fast

### fail-fast

**fail-fast：**使用迭代器遍历一个线程不安全的集合类时，在遍历过程中对集合对象的结构进行了修改（增加、删除），会直接抛出ConcurrentModifiedException

原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果结构发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。

注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。

场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。

### fail-safe

**fail-safe：**采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。

原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。

缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。

场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。

## 4、线程池的作用？各个参数的意义，工作原理以及拒绝策略

特点：线程复用，控制最大并发数，管理线程

好处：降低资源消耗，提高响应速度，提高线程的可管理性

线程池参数

~~~java
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }
~~~

1、corePoolSize：线程池的常驻核心线程数

2、maximumPoolSize：线程池中能容纳同时执行的最大线程数，必须大于1

3、keepAliveTime：多余的空闲线程的存活时间。即线程数大于核心线程数且空闲时间达到该值最自动销毁多余线程。

4、unit：keepAliveTime的单位

5、workQueue：任务队列，被提交但尚未执行的任务。

6、threadFactory：创建线程的工厂，**一般用默认的即可**

7、handler：拒绝策略，表示当队列满了，并且工作线程等于线程池中能容纳的最大线程数时如何来拒绝请求执行的runable的策略

工作原理？

1、线程池创建后等待请求

2、当调用execute()方法添加一个请求任务时，线程池会做出如下判断：
  2.1如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；
  2.2如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列；
  2.3如果这个时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；
  2.4如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行。
3、当一个线程完成任务时，它会从队列中取下一个任务来执行。
4、当一个线程无事可做超过一定的时间（keepAliveTime）时，线程会判断，如果当前运行的线程数大于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到corePoolSize的大小。

拒绝策略？

四种拒绝策略

1、AbortPolicy（默认）：直接抛出RejectExecutionException异常

2、CallerRunsPolicy：该策略既不会抛弃任务也不会抛出异常，而是将任务退回

3、DiscardPolicy：该策略默默地丢弃无法处理的任务，不予处理也不抛任何异常。

4、DiscardOldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务。

## 5、谈谈你对AQS的理解

AQS（AbstractQueueSynchronizer)，抽象队列同步器，通过内置的FIFO队列来完成线程获取资源的排队工作，尽可能的避免线程阻塞引起的不必要的开销。（模板设计模式），子类只需实现特定的接口即可使用。（如ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）

以ReentrantLock为例

~~~java
//获取锁的过程（非公平队列）
final void lock() {
    //首先进行CAS设置，即多线程如果交替持有同步状态，不需要入队等显示同步
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        //同步过程
        acquire(1);
}

//释放锁的过程
public void unlock() {
    sync.release(1);
}

//AQS的方法
public final void acquire(int arg) {
    //tryAcquire（子类实现）再次进行获取锁，或者该线程以持有锁获取再重入
    //调用AQS的方法acquireQueued(addWaiter(Node.EXCLUSIVE),args)
    if (!tryAcquire(arg) &&acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}

//ReentrantLock的tryAcquire调用
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    //获取当前队列的同步状态
    int c = getState()；
    //再次尝试CAS
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    //可重入判定
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
   	//获取失败
    return false;
}

//AQS方法
private Node addWaiter(Node mode) {
    //根据节点状态创建节点
    Node node = new Node(Thread.currentThread(), mode);
    // Try the fast path of enq; backup to full enq on failure
    Node pred = tail;
    //加入队列尾部，如果成功，直接返回
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    //循环CAS加入队列中，直到加入成功为止
    enq(node);
    return node;
}
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
//AQS方法
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        //死循环获取锁
        for (;;) {
            //获取前一个节点
            final Node p = node.predecessor();
            //前一个为头结点并且当前节点获取同步状态成功，进行相关操作，返回
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            //判断当前节点是否要阻塞，如果前面为true，根据短路原理才会将当前线程阻塞
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}

//释放锁的过程
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        //唤醒队列的下一个节点
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}

~~~

## 6、Synchronized相关

## 7、手写双重检查单例模式

~~~java
public class Singleton{
    private static volatile Singleton instance;
    private Singleton(){
        
    }
    public static Singleton getInstance(){
        if(instance==null){
            synchronized(Singleton.class){
                if(instance==null)
                    instance=new Singleton();
                
            }
        }
        return instance;
    }
}
~~~

## 8、抽象类和接口的区别

抽象类体现的是一种is-a关系，类似于设计模式的模板设计模式，子类与父类具有相同的特性，即在概念上应该是相同的，强调所属关系，而接口是一种行为型的实现方式，更多的是表达出实现某种行为，一种like-a关系，强调特定功能的实现，抽象类是对一组具有相同属性和方法的逻辑上有关系的事物的一种抽象，而接口则是对一组具有相同属性和方法的逻辑上不相关的事物的一种抽象

抽象类只可以单继承，而接口可以多实现。

接口成员变量默认为public static final，必须赋初值，不能更改。抽象类中所有成员默认为default，可以在子类中重新定义，也可被重新赋值。

接口方法默认都是public、abstract的，可以有默认实现，抽象类的抽象方法被abstrct修饰，可以为public，也可以为protected。

## 9、访问限定符

| 访问修饰符 | 本类 | 本包 | 非本包子类 | 不同包非子类 |
| :--------: | :--: | :--: | :--------: | :----------: |
|   public   |  √   |  √   |     √      |      √       |
| protected  |  √   |  √   |     √      |              |
|  default   |  √   |  √   |            |              |
|  private   |  √   |      |            |              |

## 10、字节流和字符流的区别

字节流一次操作一个字节的大小，字符流一次操作两个字节的大小。

字节流在操作的时候本身是不会用到缓冲区（内存）的，是与文件本身直接操作的，而字符流在操作的时候是使用到缓冲区的

字节流在操作文件时，即使不关闭资源（close方法），文件也能输出，但是如果字符流不实用close（）方法的话，则不会输出任何内容，说明字符流用的是缓冲区，并且可以使用flush方法强制进行刷新缓冲区，这时才能在不close的情况下输出内容。

## 11、Java NIO相关

jdk1.4开始提供了一系列改进的输入/输出新特性，被统称为NIO（同步非阻塞IO），三大核心组件：Channel、Buffer、Selector

NIO面向缓冲区、以块的方式编程，而传统BIO是面向流的。

BIO基于字节流或字符流进行操作，而NIO基于Channel（通道）和Buffer（缓冲区）进行操作，数据总是由通道读取到缓冲区中，或者从缓冲区写入到通道中。Selector（选择器）用于监听多个通道的事件（比如：连接请求、数据到达等），因此使用单个线程就可以监听多个客户端通道

Selector：

1、Java的NIO，用非阻塞的IO方式，可以用一个线程处理多个的客户端连接，就会使用到Selector（选择器）

2、Selector能够检测多个注册的通道上是否有事件发生（注意：多个Channel以事件的方式可以注册到同一个Selector），如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只使用一个单线程来管理多个通道，也就是管理多个连接和请求。

3、只有在连接/通道真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程

Channel：

类似于流，但有些区别：

1、通道可以同时进行读写，而流只能读或只能写。

2、通道可以实现异步读写数据。

3、通道可以从缓冲区读取数据，也可以写数据到缓冲区。

Buffer：

缓冲区本质上是一个可以读写数据的内存块，可以理解成是一个容器对象（含数组），该对象提供了一组方法，可以更轻松地使用内存块，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。Channel提供从文件、网络读取数据的渠道，但是读取或写入数据都必须经由Buffer。

select、poll、epoll的区别  <https://www.cnblogs.com/cainingning/p/9556642.html>

select,poll,epoll都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个描述符，一个某个描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。但select,poll,epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责读写，也就是说这个读写过程是阻塞的，而异步I/O则不需自己负责读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

select的缺点：

1、每次调用select都需要把fd集合（代表文件描述符的位数组）从用户态拷贝到内核态，这个开销在fd很多时会很大

2、同时每次调用select都需要在内核遍历传递过来的所有fd，同样在fd很多时开销大

3、select支持的文件描述符数量太小了，默认是1024

poll与select类似，不过没有文件描述符数量的限制，同样需要全部遍历

epoll：

epoll可以同时支持水平触发和边缘触发（Edge，Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发）。epoll中当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是代表一个就绪描述符数量的值，只需要epoll指定的一个数组中依次取得相应数量的文件即可，这里也使用了内存映射(mmap)技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销

总结：

1、select、poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替，而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，不同的是select和poll在醒着的时候需要遍历整个fd集合，而epoll在“醒着”的时候只需要遍历一下就绪链表是否为空就行了，节省了大量CPU的时间。

2、select、poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列），这也能节省不少开销。

## 12、双亲委派机制？什么时候会失效？

失效情况<https://blog.csdn.net/yangcheng33/article/details/52631940>

个人理解：Java中的SPI的接口是Java核心库的一部分，由启动类加载器加载的，无法扫描到SPI的实现类，需要使用应用类加载器对其进行加载，即采用TCCL来进行加载。

## 13、FULL GC触发的条件以及解决策略

1、System.gc()来建议JVM进行full gc

2、老年代空间不足

3、元空间内存达到阈值

4、堆中产生的大对象超过阈值

5、老年代连续空间不足

## 14、继承/装饰者模式/动态代理

1、继承

被增强对象不能变

增强内容不能变

2、装饰者模式

被增强对象可变

增强内容不可变

3、动态代理

被增强对象可变

增强内容可变

~~~java
Object proxy=Proxy.newInstance(ClassLoader classLoader,Class[] interfaces,InvocationHandler h);
~~~



# 计算机网络

## 1、在浏览器的url栏里输入一个https的请求会发生什么？

1、DNS解析

2、TCP连接

3、发送HTTP请求

4、服务器处理请求并返回HTTP报文

5、浏览器解析

6、连接结束

## 2、UDP相关问题

面向报文、无连接、尽最大努力交付，首部开销小

首部16位源端口、16位目的端口、16位长度、16位检验和。

## 3、TCP相关问题

1、面向连接、面向字节流、全双工通信、只有两个端点，端对端

### TCP头部

16位源端口号、16位目的端口号、32位序号、32位确认号、4位头部长度、6位保留、6个控制位（URG、ACK、PSH、RST、SYN、FIN），16位窗口、16位检验和、16位紧急指针

手绘3次握手连接、4次握手关闭过程

![1582517060242](面经总结.assets/1582517060242.png)

**连接为什么需要三次握手？两次握手的问题在哪里？**

主要是为了防止已失效的连接请求报文段突然又传送到了服务器端，服务器传回SYN+ACK，若已连接，客户端根据目前状态会自动丢弃该报文段，不会重新建立连接。

![1582517785618](面经总结.assets/1582517785618.png)

**为什么客户端最后还需要等待2MSL？**

1、保证客户端发送的最后一个ACK报文段能够顺利到达服务器，因为这个ACK报文段可能会丢失，若服务器收不到，则服务器会进行重传，客户端在这个2MSL时间段收到这个重传的报文，接着给出回应报文，重启2MSL计时器

2、防止已失效的连接请求报文段出现在本连接中。等待2MSL过程会将连接过程中产生的所有报文段都从网络中消失。使新的连接过程中不会出现旧的连接请求报文段。

**如果已经建立连接，客户端出现故障如何？**

TCP设有一个保活计时器，服务器每收到一次客户端数据，就会重新激活保活计时器，若时间达到，则会发送探测报文，若连续10次没有相应，服务器就认为客户端出了故障，接着就关闭这个连接。

### TCP如何保证可靠传输

1、以字节为单位的滑动窗口技术，发送端的窗口大小由接收端窗口大小决定

2、确认和重传机制

3、数据校验

4、累计确认以及选择确认机制

### TCP如何进行流量控制

TCP采用滑动窗口进行流量控制，在建立连接时，接受方会提供其当前能接受的窗口(rwnd)大小，当前客户端根据该窗口大小动态的调整窗口大小进行流量控制。

TCP连接的乙方收到对方的零窗口通知，就启动持续计时器，若好次需计时器设置的时间到期，就发送一个零窗口探测报文段。

### TCP如何进行拥塞控制

1、慢开始和拥塞避免

2、快重传和快恢复

拥塞窗口（cwnd）在达到慢开始门限之前指数增长，到达慢开始门限后，采用拥塞避免算法，加法增大，若出现网络拥塞，调整慢开始门限为当前拥塞窗口大小的一半，将cwnd调整为1重新开始慢开始算法增长。

快重传指的是发送方连续收到3个冗余ACK来检测丢包的发生，同时冗余ACK也用于网络拥塞的检测，快恢复即连续收到3个冗余ACK时，就执行“乘法减小”算法，把慢开始门限ssthresh设置为出现拥塞发送方cwnd的一半，与慢开始不同的是它把cwnd的值设置为慢开始的门限sshresh改变后的数值，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。

## 4、Cookie和Session



# 数据库相关

## 一条SQL执行很慢的原因

分两种情况

1、偶尔执行很慢

​	（1）、数据库刷新脏页

​			①redo被写满，数据库在进行同步数据

​			②内存不够，一次查询的太多，又恰好碰到查询的内容不在内存中，需要申请内存，且内存不足，需要进行换页操作，如果是脏页还得先刷新再换出。

​	（2）、拿不到锁

​		当前SQL语句涉及到的锁被别人使用，只能等待别人释放锁

2、一直执行很慢

​	（1）、没有用到索引

​		没有建索引，建了索引没有被用上，索引要符合最左匹配原则，对索引列进行函数操作或运算操作等会另索引失效，从而导致全表扫描

## 间隙锁是什么？解决了什么问题？

事务中使用范围条件而不是相等条件检索数据，会对符合条件的已有记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙”，InnoDB也会对这个“间隙加锁”，即使当前索引的记录不存在。

主要解决了事务中的幻读问题

## 数据库三范式

第一范式：每个字段都是原子的，不能再分解

第二范式：表必须有主键，主键可以是单个属性或几个属性的组合，非主属性必须完全依赖主键而不能部分依赖主键

第三范式：没有传递依赖；非主属性必须直接依赖主键，而不能间接依赖主键。

## count(1)、count(*)、count(列名)以及执行效率

count(1)：忽略所有列，用1代表代码行，统计结果时包括列为null的情况

count(*)：包括了所有列，相当于行数，统计结果时包括列为null的情况

count(列名)：只包括列名的那一列，统计结果会忽略列值为空的计数，即某个字段为null时不统计。

当列名为主键时，count(列名)比count(1)快。

列名不为主键时，count(1)比count(列名快)。

表有多个列没有主键时，count(1)的执行效率优于count(*)

表只有一个字段，count(*)效率最优

## MVCC

MVVC值在READ COMMITED和REPEATABLE READ两个隔离级别下工作。

MVCC机制最核心的在于undolog和ReadView

# Spring相关

## 声明式事务

# 智力题

## 一个5L桶、一个3L桶，怎样得到4L桶

BFS遍历搜索，无向图求最短路径

~~~java
public class WaterPuzzle {

    boolean[] visited;
    int[] pre;
    int end=-1;
    public WaterPuzzle(){
        visited=new boolean[100];
        pre=new int[100];
        Queue<Integer> queue=new LinkedList<>();
        queue.offer(0);
        visited[0]=true;
        while(!queue.isEmpty()){
            int curr=queue.poll();
            int a=curr/10,b=curr%10;
            List<Integer> nexts=new ArrayList<>();
            //给5L的桶装满
            nexts.add(5*10+b);
            //给3L的桶装满
            nexts.add(a*10+3);
            //倒掉5L桶里的水
            nexts.add(b);
            //倒掉3L桶里的水
            nexts.add(a*10);
            //a最多能向b桶中倒多少水
            int x=Math.min(a,3-b);
            nexts.add((a-x)*10+(b+x));
            //b最多能向a桶中倒多少水
            int y=Math.min(5-a,b);
            nexts.add((a+y)*10+(b-y));
            for(int next:nexts){
                if(!visited[next]){
                    queue.add(next);
                    visited[next]=true;
                    pre[next]=curr;
                    if(next%10==4||next/10==4) {
                        end=next;
                        return;
                    }
                }
            }
            if(end!=-1) break;
        }
    }

    public Iterable<Integer> result(){
        List<Integer> res=new ArrayList<>();
        if(end==-1) return res;
        int curr=end;
        while(curr!=0){
            res.add(0,curr);
            curr=pre[curr];
        }
        return res;
    }
~~~

## 64匹马、8个跑道、多少轮选出最快的4匹

前8轮：首先分成8组分别赛8轮，每组淘汰最后的4匹马，目前共剩8组，每组4匹马；

第9轮：8组的第一再进行一次比较，选出最快的4组来，目前剩16匹马；

第9轮的第一一定是最快的那匹马，且该马所在的组中剩余3匹马都有可能是剩下最快的3匹，第二名所在的组只有前3名可能是剩下最快的3匹，第三名所在的组只有前2名可能是最快的，而第四名所在的组只有第一名可能是最快的，此时共剩9匹马；

第10轮：选择第一名所在组的前2匹马和其余6匹马进行比较，如果第一名所在组的前2匹马不是第一第二，则最快的4匹马被确定，结束，如果第一名所在组的前两匹马是第一第二，此时还需要再进行一次比较。

第11轮：排除第10轮最快的那匹，剩余8匹再进行一次比较，取前2名，即可得到最快的8匹。

综上所述，最少需要10轮，最多需要11轮。

# 消息队列

## 引入消息队列的目的？

优点：

1、解耦

2、异步

3、削峰

缺点：

1、降低了系统的可用性

2、系统复杂性提升，消息重复消费问题，消息丢失问题，消息传递的顺序性保证

3、一致性问题，收到消息的服务未正常处理主业务却正常返回了。

ActiveMQ、RabbitMQ、RocketMQ、Kafka异同

## RabbitMQ的高可用性保证

1、单机模式

2、普通集群（集群内节点共用主机数据，其它节点只保存主机的元数据）

3、镜像集群（集群内的每个节点数据完全一致）

## RabbitMQ如何保证消息可靠传输

消息丢失有三种情况，

1、生产者丢失了数据

​	可以通过事务机制或手动confirm机制来确保生产者消息成功到达mq中

2、RabbitMQ弄丢了数据

​	可以采用持久化技术保证消息尽可能的不丢失

3、消费者弄丢了数据

​	手动ack机制，即消息正确消费后对消息进行一个确认，否则其它消费者进行处理

## RabbitMQ如何保证消息的顺序性

拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理

## 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

恢复消费者，部署多倍临时消费者，让消费者转发到临时消费者的队列中，让临时消费者进行消费，提升效率。

# 分布式搜索引擎

# 缓存

## Redis的过期策略有哪些？LRU算法手写

redis采用定期删除+惰性删除两种策略

定期删除即一段时间检查一定数量的键是否过期，惰性删除即键检查时进行删除。

## Redis的高并发和高可用如何保证？redis的主从复制，redis的哨兵原理

redis高并发保证：主从架构，一主多从，一般来说，很多项目其实就够了，单主写入数据，单机几万QPS，多从用来查询数据

redis高并发同时，还需要容纳大量的数据：一主多从，每个实例都容纳了完整的数据，比如redis主就10G的内存量。如果缓存要容纳的数据量很大，几十G、T、需要redis集群配置。

redis高可用，主从架构部署加上哨兵就可以保证。

redis进行集群可以支持高并发访问，主从架构，主负责写，并且将数据同步复制到其他的slave节点，从节点负责读，所有读请求全部走从节点

![1587387604957](面经总结.assets/1587387604957.png)

sync命令和psync命令的区别

psync命令的实现

**复制偏移量**

**复制积压缓存区**

**服务器运行ID**

slave节点不会过期key，如果master节点过期了一个key或者通过LRU淘汰了一个key，会模拟一条del命令发送给slave

redis高可用架构叫做故障转移，failover也叫做主备切换

sentinal是redis集群中非常重要的一个组件，主要功能如下：

1、**集群监控**，负责监控redis master和slave进程是否正常工作

2、**消息通知**，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员

3、**故障转移**，如果master node挂掉了，会自动转移到slave node上

4、**配置中心**，如果故障转移发生了，通知client客户端新的master地址

哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作

1、故障转移时，判断一个master node是否宕机了，需要大部分的哨兵同意才行，涉及到了分布式选举的问题

2、即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，哨兵作为高可用的保证应该是集群的

哨兵的核心知识：

1、哨兵至少需要3个实例来保证自己的健壮性

2、哨兵+redis主从的部署架构是不会保证数据零丢失的，只能保证redis集群的高可用性

经典3节点哨兵集群

![1587391741279](面经总结.assets/1587391741279.png)

## Redis的数据丢失问题

1、异步复制导致的数据丢失：master节点向slave节点的同步是异步的，可能有部分数据还没有同步，master宕机，则数据丢失

2、脑裂导致的数据丢失：由于网络问题master主节点，出现了异常性的，有相同数据，相同工作的两个节点。旧master节点仍然和客户端保持连接，所写入的数据在重新连入集群内后会丢失

如何解决？

min-slaves-to-write:1

min-slaves-max-lag:10

即要求至少有一个slave数据复制和同步的延迟不超过10秒

哨兵选举新节点的因素：

1、跟master断开连接的时长

2、slave的优先级

3、复制offset

4、run id

选举算法

对所有的slave进行一个排序

1、按照slave优先级排序，slave priority越低，优先级就越高

2、如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级越高

3、如果上面两个条件都相同，那么选择一个run id较小的那个slave

## Redis持久化机制

redis持久化的意义在于故障恢复

RDB

AOF

## Redis集群模式的工作原理

redis cluster可以支撑N个redis master node，每个master node都可以挂载多个slave node

redis cluster（多master+读写分离+高可用）

只需要基于redis cluster去搭建redis集群，不需要手工搭建replication复制+主从架构+读写分离+哨兵集群+高可用

redis cluster对比replcation+sentinal

数据量少的话自己搭建，redis cluster主要是针对海量数据+高并发+高可用的场景

分布式存储的核心算法

hash->一致性hash算法->hash slot算法

redis cluster架构下每个redis开放两个端口，高端口节点用于节点端的通信

传统hash算法在任意一个master宕机后大量数据需要重新计算写入缓存，风险大

一致性hash算法，master节点的hash值组成一个环，key计算hash后再环上找到下一个位置，尽可能的减少故障引起的集群数据不一致问题，数据倾斜问题可以通过虚拟节点来解决，将每个机器节点进行多次哈希使环中某个节点存在多个实例（Dubbo的负载均衡、Redis集群用到了这个思想）

hash slot：切分成16384个hash slot，每个节点保存一定数量的hash slot，任何一台机器宕机后，key找到的是hash slot，只有宕机的那部分数据会暂时失效，redis cluster在某个节点宕机后会对hash slot进行重分配

## Redis节点间的内部通信机制

## Redis缓存雪崩和缓存穿透

## 缓存双写一致性问题

Cache Aside Pattern

1、读的时候，先读缓存，缓存没有的话，再去读数据库，同时将数据放入数据库中

2、更新的时候先删除缓存然后再更新缓存

如果更新的时候是对缓存进行更新的话代价比较大，因为更新后的数据不一定会被用到，即一个懒加载的过程

数据库与缓存双写不一致问题

问题1：先修改数据库再删除缓存，如果删除缓存失败，如果失败，则数据库为新数据，缓存中仍为旧数据出现不一致

思路：先删除缓存后更新数据库。如果删除数据库失败了，缓存为空，不会出现不一致的情况

问题2：数据发生变更，先删除缓存，然后去修改数据库，此时还没修改完成，另一个请求读取数据又放到了缓存中，数据库完成了修改，出现了数据不一致。

思路：对某一商品的更新操作、查询如果发现缓存中没有数据的操作，经过哈希计算取模后使其都路由到同一个JVM进程中。如果发现更新操作后面已有读取操作，则可不必路由到同一队列，在自旋一段时间后

# 分布式相关知识

## 分布式系统如何保证调用顺序性

使请求全部路由到一个系统的一个队列内。或者分布式锁来保证

## 设计一个RPC框架

1、服务注册中心模块，服务调用肯定要考虑服务注册中心，保留各个服务的信息

2、代理模块，通过接口获得动态代理的类，通过该类找到服务的具体地址

3、负载均衡算法，具体是找哪个机器？

4、网络模块和序列化相关，底层网络通信模块和协议

## Zookeeper

### 数据结构图

![image-20200718155623839](/Users/gy-mac/Downloads/面试相关/笔记/面经总结.assets/image-20200718155623839.png)

图中每一个节点称为一个Znode。每个Znode由3部分组成：

1、**stat**：此为状态信息，描述Znode版本，权限等信息

2、**data**：与该Znode有关的数据

3、**children**：该Znode下的子节点

### 节点

Zookeeper的节点类型有两种，分别为**临时节点**和**永久节点**，节点类型在创建时即被确定，并且不能改变。

**临时节点**：该节点的生命周期依赖于创建他们的对话。一旦**会话结束，临时节点将被自动删除**，也可以手动删除，**临时节点不允许拥有子节点**

**永久节点**：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删除操作的时候才能被删除

Znode还有一个**序列化**特征，如果创建的时候指定的话，该node的名字后面会**自动追加一个不断增加的序列号**。序列号对于此节点的父节点来说是唯一的，这样便会记录每个子节点创建的先后顺序，格式为"%10d"（10位数字，没有数值的数位用0补充，例如"0000000001"，这样便会存在四种类型的节点。

### Watcher

Zookeeper提供了"分布式数据发布/订阅"功能，一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能让多个订阅者同时监听同一个主题对象，当这个主题对象发生变化时，会通知所有订阅者，使他们能够做出相应的处理。Zookeeper中引入了**Watcher机制来实现了这种分布式的通知功能**。客户端可以向服务端注册一个监听，当服务端的一些事件触发了这个Watcher，那么就会像注册过监听的客户端发送一个通知。触发的事件种类很多，有"节点创建、节点删除、节点改变、子节点改变等。

总的来说Watcher为以下三个过程：**客户端向服务端注册Watcher**、**服务端事件发生触发Watcher**、**客户端回调Watcher得到触发事件情况**

#### watcher机制的特点

**1、一次性触发**

事件发生触发监听，相同的事件只会触发一次

**2、事件封装**

Zookeeper使用WatchedEvent对象来封装服务端事件并传递，该结构包含了每一个事件的三个基本属性：

通知状态（keeperState），事件类型（EventType）和节点路径（path）

**3、event异步发送**

watcher的通知事件从服务端发送到客户端是异步的

**4、先注册再触发**

### 选举机制

Zookeeper的默认算法是FastLeaderElection，采用**投票数大于半数则胜出**的逻辑。

相关概念：

1、服务器Id：对服务器进行编号

2、选举状态：

LOOKING：竞选状态

FOLLOWING：随从状态，同步leader状态，参与投票

OBSERVING：观察状态，同步leader状态，不参与投票

LEADING：领导者状态

3、数据ID：

服务器中存放的最新数据version，值越大说明数据越新，在选举算法中数据越新权重越大

4、逻辑时钟

也叫投票的次数，**同一轮投票过程中的逻辑时钟是相同的**。每投完一次票这个数据就会增加，然后与接收到的其它服务器返回的投票信息中的数值相比，根据不同的值做出不同的判断。

#### 全新集群选举

五台服务器，均没有数据，编号位1，2，3，4，5，按编号依次启动，选举过程：

1、1启动，给自己投票，其它机器还没有启动所以它收不到反馈信息，1状态一直属性Looking

2、2启动，给自己投票，与1交换信息，2>1，2胜出但是投票数没有大于服务器总数的半数，两个服务器状态依然是LOOKING

3、3启动，给自己投票，与1，2交换信息，3最大，且投票数大于半数，3称为leader，1，3成为小弟

4、4启动，给自己投票，与1，2，3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能称为小弟

5、同理4

#### 非全新集群选举

对于运行正常的Zookeeper集群，中途有机器down掉，需要重新选举时，选举过程就需要加入**数据ID**、**服务器ID**和**逻辑时钟**。

选举的标准称为：

1、逻辑时钟小的选举结果被忽略，重新投票

2、统一逻辑时钟侯，数据id大的胜出

3、数据id相同的情况下，服务器id大的胜出

### 典型应用

#### 数据发布与订阅（配置中心）

利用Watcher机制，适合数据量较小的场景，数据更新较快

#### 命名服务（Naming Service）

在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以时集群中的机器，提供的服务地址，远程对象等等--这些我们都可以统称他们位名字。调用ZK创建节点的API，能够很容易创建一个全局唯一的path

#### 分布式锁

分布式锁，这个主要得益于Zookeeper保证了数据的"**强一致性**"，锁服务可以分为两类，一个是保持独占，另一个是控制时序。

**保持独占**：就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。例如所有客户端都去创建/lock/node节点，最终成功创建的那个客户端也即拥有了这把锁

**控制时序**：就是所有试图来获取这个锁的客户端，最终都是会被安排执行，只是有一个全局时序。做法和上面基本类似，只是这里父节点/lock已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制）Zk的父节点维持一份sequence，保证子节点创建的时序性，从而也形成了每个客户端的全局时序。

### ZAB协议

ZAB（zookeeper 原子消息广播协议），是为Zookeeper专门设计的一种支持崩溃恢复的原子广播协议，Zookeeper主要依赖ZAB协议来实现分布式数据的一致性，基于该协议，Zookeeper实现了一种**主备模式**的系统架构来保持集群中各个副本之间的**数据一致性**，同时崩其崩溃恢复过程中也确保zk集群的**高可用性**（HA）

Zookeeper使用一个单一主进程来接收并处理客户端的所有事务请求，并采用ZAB的原子广播协议，将服务器数据的状态变更以事务Proposal的形式广播到所有的副本进程上，并且ZAB协议能够保证一个全局的变更序列。

**ZAB协议的核心是定义了对于那些会改变Zookeeper服务器数据状态的事务请求的处理方式。**

Zookeeper客户端会随机连接到Zookeeper集群的一个节点，如果是读请求，就直接从当前节点中读取数据；**如果是写请求且当前节点不是leader，那么节点就会向leader提交事务，leader会广播事务**，只要有超过半数节点写入成功，读写请求就会被提交（类2PC协议）

问题

1、主从架构下，leader崩溃，数据一致性怎么保证？

2、选举leader的时候，整个集群无法处理写请求的，如何快速进行leader选举

**ZAB**协议重要的就是：

1、消息广播协议（leader向其它节点广播事务）

2、leader选举（快速选举，集群刚启动时leader崩溃或leader与集群中超过一般的节点断连后）

3、leader重新选举后，如何进行数据同步到一致状态

ZAB协议的两种基本模式：崩溃恢复模式和消息广播模式

当系统启动或leader出故障，进入故障恢复模式，开启新的一轮选举，选举产生的leader与过半的follower进行同步，使数据一致，当与过半的机器同步完成后，就退出恢复模式，进入消息广播模式。当一台遵从ZAB协议的服务器启动时，如果检测到leader在广播消息，会自动进入恢复模式，当其完成与leader 的同步之后，则进入广播模式。即**zk可以保证易扩展性（没有进行数据同步，就不能加入真正可用的follower列表）**

### 消息广播

当集群中已有过半的follower与leader服务器完成了状态同步，那么整个zk集群就可以进入消息广播模式了。

如果集群中的其他节点收到客户端的**事务请求**，那么这些非leader服务器会首先将这个事务请求转发给leader服务器。

该协议类似于一个2PC提交过程，针对每个客户端的事务请求，leader服务器会为其生成对应的事务Proposal，并将其发送给集群中其余所有的机器，然后再分别收集各自的选片，最后进行事务提交。

相比较于传统的二阶段提交，ZAB协议最大的区别就是**移除了中断逻辑**，follower要么回ACK给leader，要么抛弃leader，在某一时刻，leader的状态与follower的状态很可能不一致，因此它不能处理leader挂掉的情况，所以ZAB协议引入了恢复模式来处理这一问题。从另一角度看，正因为ZAB的广播过程不需要终止事务，也就是说不需要所有的follower都返回ACK才进行commit，而是只需要合法数量（2f+1台服务器中的f+1台）的follower，也提升了整体的性能。**不能正常反馈的节点就抛弃leader，然后进入数据同步阶段，和集群达成一致**

### 崩溃恢复（Leader选举）

ZAB协议会让ZK集群进入崩溃恢复的模式有：

1、当服务框架在启动过程中

2、当Leader服务器出现网络中断，崩溃退出与重启等异常情况

3、当集群中已经不存在过半的服务器与Leader服务器保持正常通信

Leader选举需要达到的再次使用的条件，需要解决以下两个问题：

1、已经被leader提交的事务需要最终被所有的机器提交（已经发出commit了）

2、保证丢弃那些只在leader上提出的事务（只在leader上提出了proposal，还没有收到回应，还没有进行提交）



